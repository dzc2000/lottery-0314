24-08-07.20:56:38.960 [main            ] INFO  AwardServiceTest       - Starting AwardServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 55190 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-07.20:56:38.961 [main            ] INFO  AwardServiceTest       - The following 1 profile is active: "dev"
24-08-07.20:56:39.797 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-07.20:56:39.799 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-07.20:56:39.826 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 17 ms. Found 0 Redis repository interfaces.
24-08-07.20:56:40.854 [main            ] INFO  Version                - Redisson 3.26.0
24-08-07.20:56:40.890 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-07.20:56:41.063 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.20:56:41.085 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.20:56:42.898 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-07.20:56:43.023 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.20:56:43.158 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.20:56:43.158 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.20:56:43.158 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035403156
24-08-07.20:56:43.181 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-07.20:56:43.194 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.20:56:43.207 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.20:56:43.207 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.20:56:43.207 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035403207
24-08-07.20:56:43.215 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-07.20:56:43.219 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.20:56:43.225 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.20:56:43.225 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.20:56:43.225 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035403225
24-08-07.20:56:43.232 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-07.20:56:43.268 [main            ] INFO  AwardServiceTest       - Started AwardServiceTest in 4.873 seconds (JVM running for 6.002)
24-08-07.20:56:43.629 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-07.20:56:43.629 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-07.20:56:43.630 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-07.20:56:43.633 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.20:56:43.633 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.20:56:43.633 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.20:56:43.671 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.20:56:43.671 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.20:56:43.671 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.20:56:43.718 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.20:56:44.111 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.20:56:44.168 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.20:56:44.195 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.20:56:44.357 [main            ] WARN  AwardRepository        - 更新中奖记录，重复更新拦截 userId:dzc giveOutPrizesAggregate:{"userAwardRecordEntity":{"awardId":101,"awardState":"complete","orderId":"690124733440","userId":"dzc"},"userCreditAwardEntity":{"creditAmount":0.929,"userId":"dzc"},"userId":"dzc"}
24-08-07.20:56:44.410 [main            ] ERROR AwardRepository        - 写入中奖记录，用户抽奖单已使用过，不可重复抽奖 userId: dzc activityId: 100301 awardId: 101
24-08-07.20:56:45.027 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.20:56:45.041 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.20:56:45.681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-07.20:56:45.681 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-07.20:56:45.681 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-07.20:56:45.691 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:56:45.691 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:56:45.691 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:56:45.692 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:56:45.692 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:56:45.692 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.20:56:45.692 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:56:45.692 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.20:56:45.692 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.20:56:45.693 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:56:45.693 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:56:45.693 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:56:45.693 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:56:45.693 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:56:45.693 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:56:51.866 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8163 ms.
24-08-07.20:56:51.870 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.20:56:51.872 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.20:56:51.872 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.20:56:51.872 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.20:56:51.879 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-07.20:56:51.880 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.20:56:52.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8899 ms.
24-08-07.20:56:52.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.20:56:52.572 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.20:56:52.572 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.20:56:52.572 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.20:56:52.575 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-07.20:56:52.575 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.20:56:54.597 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10853 ms.
24-08-07.20:56:54.598 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.20:56:54.600 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.20:56:54.600 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.20:56:54.600 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.20:56:54.605 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-07.20:56:54.605 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.20:58:53.194 [main            ] INFO  RaffleActivityControllerTest - Starting RaffleActivityControllerTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 55259 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-07.20:58:53.195 [main            ] INFO  RaffleActivityControllerTest - The following 1 profile is active: "dev"
24-08-07.20:58:54.022 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-07.20:58:54.024 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-07.20:58:54.053 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 19 ms. Found 0 Redis repository interfaces.
24-08-07.20:58:54.863 [main            ] INFO  Version                - Redisson 3.26.0
24-08-07.20:58:54.890 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-07.20:58:55.023 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.20:58:55.035 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.20:58:56.845 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-07.20:58:56.936 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.20:58:57.021 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.20:58:57.021 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.20:58:57.021 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035537020
24-08-07.20:58:57.032 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-07.20:58:57.038 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.20:58:57.043 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.20:58:57.043 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.20:58:57.043 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035537043
24-08-07.20:58:57.046 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-07.20:58:57.048 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.20:58:57.051 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.20:58:57.051 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.20:58:57.051 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035537051
24-08-07.20:58:57.056 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-07.20:58:57.078 [main            ] INFO  RaffleActivityControllerTest - Started RaffleActivityControllerTest in 4.326 seconds (JVM running for 5.276)
24-08-07.20:58:57.371 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-07.20:58:57.371 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-07.20:58:57.371 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-07.20:58:57.374 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.20:58:57.374 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.20:58:57.374 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.20:58:57.376 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.20:58:57.376 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.20:58:57.376 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.20:58:57.382 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-07.20:58:57.382 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-07.20:58:57.382 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-07.20:58:57.540 [main            ] INFO  RaffleActivityController - 活动抽奖 userId:dzc activityId:100301
24-08-07.20:58:57.640 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.20:58:57.955 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.20:58:58.047 [main            ] INFO  RaffleActivityController - 活动抽奖，创建订单 userId:dzc activityId:100301 orderId:446778534501
24-08-07.20:58:58.067 [main            ] INFO  DefaultLogicChain      - 抽奖责任链-默认处理 userId: dzc strategyId: 100006 ruleModel: rule_default awardId: 102
24-08-07.20:58:58.067 [main            ] INFO  AbstractRaffleStrategy - 抽奖策略计算-责任链 dzc 100006 102 rule_default
24-08-07.20:58:58.068 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.20:58:58.085 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.20:58:58.099 [main            ] INFO  RuleStockLogicTreeNode - 规则过滤-库存扣减 userId:dzc strategyId:100006 awardId:102
24-08-07.20:58:58.101 [main            ] INFO  RuleStockLogicTreeNode - 规则过滤-库存扣减-成功 userId:dzc strategyId:100006 awardId:102
24-08-07.20:58:58.130 [main            ] INFO  DecisionTreeEngine     - 决策树引擎【规则树-兜底奖励】treeId:tree_luck_award node:rule_stock code:0001
24-08-07.20:58:58.130 [main            ] INFO  AbstractRaffleStrategy - 抽奖策略计算-规则树 dzc 100006 102 null
24-08-07.20:58:58.345 [main            ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-07.20:58:58.345 [main            ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-07.20:58:58.389 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.20:58:58.389 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.20:58:58.389 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035538389
24-08-07.20:58:58.397 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.20:59:00.023 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.20:59:00.048 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.20:59:06.308 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8922 ms.
24-08-07.20:59:06.311 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.20:59:06.608 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 8202 ms.
24-08-07.20:59:07.480 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 2147483646 disconnected.
24-08-07.20:59:07.480 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 2147483646 disconnected.
24-08-07.20:59:07.481 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 2147483646 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.20:59:07.481 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 2147483646 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.20:59:07.481 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.20:59:07.481 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.20:59:12.538 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:59:12.538 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:59:12.539 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.20:59:12.538 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:59:12.539 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:59:12.539 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.20:59:12.538 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:59:12.540 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:59:12.540 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.20:59:12.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:59:12.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:59:12.541 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:59:12.542 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:59:12.541 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.20:59:12.543 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.20:59:12.546 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.20:59:12.546 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.20:59:12.546 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.20:59:12.547 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.20:59:12.547 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.20:59:12.547 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.20:59:12.547 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.20:59:12.547 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.20:59:12.548 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.20:59:12.574 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-07.20:59:12.575 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-07.20:59:12.576 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.20:59:12.576 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.20:59:12.577 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-07.20:59:12.577 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.20:59:12.590 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":102,"awardTitle":"OpenAI会员卡","userId":"dzc"},"id":"87401387697","timestamp":1723035538149}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$d738ceb4.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.20:59:12.593 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-07.20:59:12.593 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_award
24-08-07.20:59:12.598 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-07.20:59:12.598 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.20:59:12.599 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-07.20:59:12.598 [main            ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":102,"awardTitle":"OpenAI会员卡","userId":"dzc"},"id":"87401387697","timestamp":1723035538149}
org.apache.kafka.common.KafkaException: Producer closed while send in progress
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:938)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.AwardRepository.saveUserAwardRecord(AwardRepository.java:105)
	at com.dzc.domain.award.service.AwardService.saveUserAwardRecord(AwardService.java:60)
	at com.dzc.trigger.http.RaffleActivityController.draw(RaffleActivityController.java:145)
	at com.dzc.test.trigger.RaffleActivityControllerTest.test_draw(RaffleActivityControllerTest.java:39)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: org.apache.kafka.common.KafkaException: Requested metadata update after close
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:126)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 42 common frames omitted
24-08-07.20:59:12.599 [main            ] ERROR AwardRepository        - 写入中奖记录，发送MQ消息失败 userId: dzc topic: send_award
24-08-07.20:59:12.599 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-07.20:59:12.611 [main            ] INFO  RaffleActivityControllerTest - 请求参数：{"activityId":100301,"userId":"dzc"}
24-08-07.20:59:12.626 [main            ] INFO  RaffleActivityControllerTest - 测试结果：{"code":"0000","data":{"awardId":102,"awardIndex":2,"awardTitle":"OpenAI会员卡"},"info":"成功"}
24-08-07.21:01:12.320 [main            ] INFO  RaffleActivityControllerTest - Starting RaffleActivityControllerTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 55306 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-07.21:01:12.321 [main            ] INFO  RaffleActivityControllerTest - The following 1 profile is active: "dev"
24-08-07.21:01:13.390 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-07.21:01:13.393 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-07.21:01:13.436 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 30 ms. Found 0 Redis repository interfaces.
24-08-07.21:01:14.391 [main            ] INFO  Version                - Redisson 3.26.0
24-08-07.21:01:14.425 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-07.21:01:14.592 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.21:01:14.613 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.21:01:17.138 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-07.21:01:17.243 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:01:17.386 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:01:17.386 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:01:17.386 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035677384
24-08-07.21:01:17.406 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-07.21:01:17.415 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:01:17.422 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:01:17.422 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:01:17.422 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035677422
24-08-07.21:01:17.428 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-07.21:01:17.431 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:01:17.438 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:01:17.438 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:01:17.438 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035677438
24-08-07.21:01:17.443 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-07.21:01:17.479 [main            ] INFO  RaffleActivityControllerTest - Started RaffleActivityControllerTest in 5.699 seconds (JVM running for 7.211)
24-08-07.21:01:17.837 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-07.21:01:17.837 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-07.21:01:17.837 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-07.21:01:17.839 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:01:17.839 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:01:17.839 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:01:17.840 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:01:17.840 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:01:17.840 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:01:17.846 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-07.21:01:17.846 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-07.21:01:17.846 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-07.21:01:17.936 [main            ] INFO  RaffleActivityController - 活动抽奖 userId:user001 activityId:100301
24-08-07.21:01:18.032 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:01:18.433 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:01:18.517 [main            ] INFO  RaffleActivityController - 活动抽奖，创建订单 userId:user001 activityId:100301 orderId:812802302516
24-08-07.21:01:18.540 [main            ] INFO  DefaultLogicChain      - 抽奖责任链-默认处理 userId: user001 strategyId: 100006 ruleModel: rule_default awardId: 108
24-08-07.21:01:18.541 [main            ] INFO  AbstractRaffleStrategy - 抽奖策略计算-责任链 user001 100006 108 rule_default
24-08-07.21:01:18.541 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:01:18.563 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:01:18.580 [main            ] INFO  RuleStockLogicTreeNode - 规则过滤-库存扣减 userId:user001 strategyId:100006 awardId:108
24-08-07.21:01:18.583 [main            ] INFO  StrategyRepository     - 策略奖品库存加锁失败 strategy_award_count_key_100006_108_0
24-08-07.21:01:18.583 [main            ] WARN  RuleStockLogicTreeNode - 规则过滤-库存扣减-告警，库存不足。userId:user001 strategyId:100006 awardId:108
24-08-07.21:01:18.584 [main            ] INFO  DecisionTreeEngine     - 决策树引擎【规则树-兜底奖励】treeId:tree_luck_award node:rule_stock code:0000
24-08-07.21:01:18.585 [main            ] INFO  RuleLuckAwardLogicTreeNode - 规则过滤-兜底奖品 userId:user001 strategyId:100006 awardId:108 ruleValue:101:1,100
24-08-07.21:01:18.634 [main            ] INFO  RuleLuckAwardLogicTreeNode - 规则过滤-兜底奖品 userId:user001 strategyId:100006 awardId:101 awardRuleValue:1,100
24-08-07.21:01:18.635 [main            ] INFO  DecisionTreeEngine     - 决策树引擎【规则树-兜底奖励】treeId:tree_luck_award node:rule_luck_award code:0001
24-08-07.21:01:18.635 [main            ] INFO  AbstractRaffleStrategy - 抽奖策略计算-规则树 user001 100006 101 1,100
24-08-07.21:01:18.946 [main            ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-07.21:01:18.946 [main            ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-07.21:01:18.979 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:01:18.979 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:01:18.979 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035678979
24-08-07.21:01:19.005 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:01:20.010 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:01:20.031 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:01:26.075 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8221 ms.
24-08-07.21:01:26.079 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:01:27.309 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 8272 ms.
24-08-07.21:01:27.637 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 9764 ms.
24-08-07.21:01:27.638 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:01:28.038 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 2147483646 disconnected.
24-08-07.21:01:28.038 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 2147483646 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:01:28.039 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:01:35.494 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 9393 ms.
24-08-07.21:01:37.305 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 9252 ms.
24-08-07.21:01:39.585 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 11913 ms.
24-08-07.21:01:48.968 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 21513 ms.
24-08-07.21:01:56.605 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 20990 ms.
24-08-07.21:01:56.705 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 17001 ms.
24-08-07.21:01:57.009 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:01:57.009 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:01:57.009 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:01:57.009 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:01:57.009 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:01:57.009 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:01:57.009 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:01:57.009 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:01:57.009 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:01:57.010 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:01:57.010 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:01:57.010 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:01:57.010 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:01:57.011 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:01:57.011 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:01:57.012 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:01:57.012 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:01:57.012 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:01:57.012 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:01:57.013 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:01:57.013 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:01:57.013 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:01:57.013 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:01:57.013 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:01:57.024 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-07.21:01:57.025 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:01:57.027 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-07.21:01:57.027 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-07.21:01:57.027 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:01:57.027 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:01:57.036 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":102,"awardTitle":"OpenAI会员卡","userId":"dzc"},"id":"87401387697","timestamp":1723035538149}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$4dfd2331.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.21:01:57.037 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-07.21:01:57.039 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:01:57.039 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_award
24-08-07.21:01:57.039 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:01:57.039 [main            ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":101,"awardTitle":"随机积分","userId":"user001"},"id":"61293584724","timestamp":1723035678653}
org.apache.kafka.common.KafkaException: Producer closed while send in progress
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:938)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.AwardRepository.saveUserAwardRecord(AwardRepository.java:105)
	at com.dzc.domain.award.service.AwardService.saveUserAwardRecord(AwardService.java:60)
	at com.dzc.trigger.http.RaffleActivityController.draw(RaffleActivityController.java:145)
	at com.dzc.test.trigger.RaffleActivityControllerTest.test_blacklist_draw(RaffleActivityControllerTest.java:51)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: org.apache.kafka.common.KafkaException: Requested metadata update after close
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:126)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 42 common frames omitted
24-08-07.21:01:57.040 [main            ] ERROR AwardRepository        - 写入中奖记录，发送MQ消息失败 userId: user001 topic: send_award
24-08-07.21:01:57.040 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-07.21:01:57.041 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-07.21:01:57.063 [main            ] INFO  RaffleActivityControllerTest - 请求参数：{"activityId":100301,"userId":"user001"}
24-08-07.21:01:57.073 [main            ] INFO  RaffleActivityControllerTest - 测试结果：{"code":"0000","data":{"awardId":101,"awardIndex":1,"awardTitle":"随机积分"},"info":"成功"}
24-08-07.21:02:03.576 [main            ] INFO  RaffleActivityControllerTest - Starting RaffleActivityControllerTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 55324 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-07.21:02:03.577 [main            ] INFO  RaffleActivityControllerTest - The following 1 profile is active: "dev"
24-08-07.21:02:04.529 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-07.21:02:04.531 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-07.21:02:04.567 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 24 ms. Found 0 Redis repository interfaces.
24-08-07.21:02:05.461 [main            ] INFO  Version                - Redisson 3.26.0
24-08-07.21:02:05.494 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-07.21:02:05.648 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.21:02:05.663 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.21:02:08.003 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-07.21:02:08.119 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:02:08.725 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:02:08.731 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:02:08.731 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035728709
24-08-07.21:02:08.802 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-07.21:02:08.819 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:02:08.839 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:02:08.840 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:02:08.840 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035728839
24-08-07.21:02:08.854 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-07.21:02:08.858 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:02:08.868 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:02:08.868 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:02:08.868 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035728868
24-08-07.21:02:08.876 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-07.21:02:08.930 [main            ] INFO  RaffleActivityControllerTest - Started RaffleActivityControllerTest in 5.936 seconds (JVM running for 7.099)
24-08-07.21:02:10.106 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:02:10.251 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-07.21:02:10.251 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-07.21:02:10.251 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-07.21:02:10.254 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:02:10.254 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:02:10.255 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:02:10.256 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:02:10.256 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:02:10.256 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:02:10.264 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-07.21:02:10.264 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-07.21:02:10.265 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-07.21:02:10.326 [main            ] INFO  RaffleActivityController - 活动抽奖 userId:user001 activityId:100301
24-08-07.21:02:10.696 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:02:10.772 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-07.21:02:10.772 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-07.21:02:10.797 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:02:10.798 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:02:10.798 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035730797
24-08-07.21:02:10.808 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:02:10.817 [main            ] INFO  RaffleActivityController - 活动抽奖，创建订单 userId:user001 activityId:100301 orderId:079340360325
24-08-07.21:02:10.855 [main            ] INFO  DefaultLogicChain      - 抽奖责任链-默认处理 userId: user001 strategyId: 100006 ruleModel: rule_default awardId: 108
24-08-07.21:02:10.857 [main            ] INFO  AbstractRaffleStrategy - 抽奖策略计算-责任链 user001 100006 108 rule_default
24-08-07.21:02:10.858 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:02:10.890 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:02:10.912 [main            ] INFO  RuleStockLogicTreeNode - 规则过滤-库存扣减 userId:user001 strategyId:100006 awardId:108
24-08-07.21:02:10.918 [main            ] INFO  StrategyRepository     - 策略奖品库存加锁失败 strategy_award_count_key_100006_108_0
24-08-07.21:02:10.919 [main            ] WARN  RuleStockLogicTreeNode - 规则过滤-库存扣减-告警，库存不足。userId:user001 strategyId:100006 awardId:108
24-08-07.21:02:10.920 [main            ] INFO  DecisionTreeEngine     - 决策树引擎【规则树-兜底奖励】treeId:tree_luck_award node:rule_stock code:0000
24-08-07.21:02:10.921 [main            ] INFO  RuleLuckAwardLogicTreeNode - 规则过滤-兜底奖品 userId:user001 strategyId:100006 awardId:108 ruleValue:101:1,100
24-08-07.21:02:11.005 [main            ] INFO  RuleLuckAwardLogicTreeNode - 规则过滤-兜底奖品 userId:user001 strategyId:100006 awardId:101 awardRuleValue:1,100
24-08-07.21:02:11.007 [main            ] INFO  DecisionTreeEngine     - 决策树引擎【规则树-兜底奖励】treeId:tree_luck_award node:rule_luck_award code:0001
24-08-07.21:02:11.007 [main            ] INFO  AbstractRaffleStrategy - 抽奖策略计算-规则树 user001 100006 101 1,100
24-08-07.21:02:18.592 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8298 ms.
24-08-07.21:02:18.598 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:02:19.163 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8880 ms.
24-08-07.21:02:19.164 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:02:19.597 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 8744 ms.
24-08-07.21:02:20.903 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10620 ms.
24-08-07.21:02:20.904 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:02:21.500 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:02:21.500 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:02:21.500 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:02:21.500 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:02:21.500 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:02:21.500 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:02:21.500 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:02:21.500 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:02:21.500 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:02:21.501 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:02:21.501 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:02:21.501 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:02:21.501 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:02:21.501 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:02:21.502 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:02:21.502 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:02:21.502 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:02:21.503 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:02:21.503 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:02:21.503 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:02:21.503 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:02:21.503 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:02:21.503 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:02:21.503 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:02:21.512 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-07.21:02:21.512 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:02:21.512 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-07.21:02:21.512 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:02:21.514 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-07.21:02:21.514 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:02:21.522 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":102,"awardTitle":"OpenAI会员卡","userId":"dzc"},"id":"87401387697","timestamp":1723035538149}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$4dfd2331.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.21:02:21.523 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-07.21:02:21.524 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_award
24-08-07.21:02:21.526 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:02:21.527 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:02:21.527 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-07.21:02:21.527 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-07.21:02:21.527 [main            ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":101,"awardTitle":"随机积分","userId":"user001"},"id":"93638410857","timestamp":1723035731018}
org.apache.kafka.common.KafkaException: Producer closed while send in progress
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:938)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.AwardRepository.saveUserAwardRecord(AwardRepository.java:105)
	at com.dzc.domain.award.service.AwardService.saveUserAwardRecord(AwardService.java:60)
	at com.dzc.trigger.http.RaffleActivityController.draw(RaffleActivityController.java:145)
	at com.dzc.test.trigger.RaffleActivityControllerTest.test_blacklist_draw(RaffleActivityControllerTest.java:51)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: org.apache.kafka.common.KafkaException: Requested metadata update after close
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:126)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 42 common frames omitted
24-08-07.21:02:21.528 [main            ] ERROR AwardRepository        - 写入中奖记录，发送MQ消息失败 userId: user001 topic: send_award
24-08-07.21:02:21.533 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-07.21:02:21.533 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-07.21:02:21.537 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:02:21.537 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:02:21.537 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035741537
24-08-07.21:02:21.540 [main            ] INFO  RaffleActivityControllerTest - 请求参数：{"activityId":100301,"userId":"user001"}
24-08-07.21:02:21.543 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":101,"awardTitle":"随机积分","userId":"user001"},"id":"61293584724","timestamp":1723035678653}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$4dfd2331.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.21:02:21.544 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: user001 topic: send_award
24-08-07.21:02:21.546 [main            ] INFO  RaffleActivityControllerTest - 测试结果：{"code":"0000","data":{"awardId":101,"awardIndex":1,"awardTitle":"随机积分"},"info":"成功"}
24-08-07.21:02:21.557 [kafka-producer-network-thread | producer-2] INFO  Metadata               - [Producer clientId=producer-2] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-07.21:02:21.557 [kafka-producer-network-thread | producer-2] INFO  Metadata               - [Producer clientId=producer-2] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:02:30.029 [main            ] INFO  RaffleActivityControllerTest - Starting RaffleActivityControllerTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 55337 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-07.21:02:30.030 [main            ] INFO  RaffleActivityControllerTest - The following 1 profile is active: "dev"
24-08-07.21:02:30.989 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-07.21:02:30.991 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-07.21:02:31.026 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 22 ms. Found 0 Redis repository interfaces.
24-08-07.21:02:31.945 [main            ] INFO  Version                - Redisson 3.26.0
24-08-07.21:02:31.979 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-07.21:02:32.133 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.21:02:32.148 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.21:02:34.486 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-07.21:02:34.621 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:02:34.798 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:02:34.798 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:02:34.798 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035754794
24-08-07.21:02:34.833 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-07.21:02:34.846 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:02:34.857 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:02:34.857 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:02:34.857 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035754857
24-08-07.21:02:34.865 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-07.21:02:34.868 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:02:34.877 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:02:34.877 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:02:34.877 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035754877
24-08-07.21:02:34.884 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-07.21:02:34.921 [main            ] INFO  RaffleActivityControllerTest - Started RaffleActivityControllerTest in 5.394 seconds (JVM running for 6.484)
24-08-07.21:02:35.137 [scheduling-1    ] INFO  UpdateAwardStockJob    - 定时任务，更新奖品消耗库存 strategyId:100006 awardId:102
24-08-07.21:02:35.195 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:02:35.404 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-07.21:02:35.404 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-07.21:02:35.404 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-07.21:02:35.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:02:35.407 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:02:35.407 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:02:35.408 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:02:35.408 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:02:35.408 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:02:35.414 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-07.21:02:35.414 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-07.21:02:35.414 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-07.21:02:35.568 [main            ] INFO  RaffleActivityController - 日历签到返利开始 userId:user002
24-08-07.21:02:35.699 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:02:35.731 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:02:35.757 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:02:35.760 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:02:35.785 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:02:35.843 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-07.21:02:35.843 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-07.21:02:35.875 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:02:35.875 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:02:35.875 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035755875
24-08-07.21:02:35.887 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:02:45.940 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 2147483646 disconnected.
24-08-07.21:02:45.942 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 2147483646 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:02:45.943 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:02:46.490 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10994 ms.
24-08-07.21:02:46.491 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:02:47.114 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 11193 ms.
24-08-07.21:02:47.313 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 11850 ms.
24-08-07.21:02:47.314 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:02:56.138 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 10167 ms.
24-08-07.21:02:57.266 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 10748 ms.
24-08-07.21:02:59.340 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 11976 ms.
24-08-07.21:03:03.280 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:03:03.280 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:03:03.281 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:03:03.281 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:03:03.280 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:03:03.281 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:03:03.281 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:03:03.281 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:03:03.281 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:03:03.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:03:03.283 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:03:03.283 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:03:03.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:03:03.283 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:03:03.283 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:03:03.285 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:03:03.285 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:03:03.285 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:03:03.286 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:03:03.286 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:03:03.286 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:03:03.286 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:03:03.286 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:03:03.286 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:03:03.300 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-07.21:03:03.301 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:03:03.302 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-07.21:03:03.303 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:03:03.303 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-07.21:03:03.303 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:03:03.321 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-07.21:03:03.323 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":102,"awardTitle":"OpenAI会员卡","userId":"dzc"},"id":"87401387697","timestamp":1723035538149}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$4dfd2331.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.21:03:03.331 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:03:03.331 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:03:03.331 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-07.21:03:03.332 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-07.21:03:03.332 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_award
24-08-07.21:03:03.334 [main            ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"user002_sku_20240807","rebateConfig":"9011","rebateType":"sku","userId":"user002"},"id":"34991446286","timestamp":1723035755752}
org.apache.kafka.common.KafkaException: Producer closed while send in progress
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:938)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:21)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:109)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:82)
	at com.dzc.trigger.http.RaffleActivityController.calendarSignRebate(RaffleActivityController.java:191)
	at com.dzc.test.trigger.RaffleActivityControllerTest.test_calendarSignRebate(RaffleActivityControllerTest.java:62)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: org.apache.kafka.common.KafkaException: Requested metadata update after close
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:126)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 42 common frames omitted
24-08-07.21:03:03.335 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，发送MQ消息失败 userId: user002 topic: null
24-08-07.21:03:11.995 [main            ] INFO  RaffleActivityControllerTest - Starting RaffleActivityControllerTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 55360 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-07.21:03:11.996 [main            ] INFO  RaffleActivityControllerTest - The following 1 profile is active: "dev"
24-08-07.21:03:13.855 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-07.21:03:13.859 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-07.21:03:13.903 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 30 ms. Found 0 Redis repository interfaces.
24-08-07.21:03:14.942 [main            ] INFO  Version                - Redisson 3.26.0
24-08-07.21:03:14.976 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-07.21:03:15.162 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.21:03:15.181 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.21:03:17.371 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-07.21:03:17.484 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:03:17.585 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:03:17.585 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:03:17.585 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035797583
24-08-07.21:03:17.614 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-07.21:03:17.627 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:03:17.652 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:03:17.653 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:03:17.653 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035797652
24-08-07.21:03:17.664 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-07.21:03:17.679 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:03:17.694 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:03:17.694 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:03:17.694 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035797694
24-08-07.21:03:17.701 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-07.21:03:17.784 [main            ] INFO  RaffleActivityControllerTest - Started RaffleActivityControllerTest in 6.544 seconds (JVM running for 7.229)
24-08-07.21:03:18.427 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-07.21:03:18.427 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-07.21:03:18.427 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-07.21:03:18.430 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:03:18.430 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:03:18.431 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:03:18.431 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:03:18.431 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:03:18.431 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:03:18.438 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-07.21:03:18.438 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-07.21:03:18.439 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-07.21:03:18.537 [main            ] INFO  RaffleActivityController - 日历签到返利开始 userId:user002
24-08-07.21:03:18.563 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:03:18.981 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:03:19.026 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:03:19.057 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:03:19.125 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，唯一索引冲突 userId: user002
org.springframework.dao.DuplicateKeyException: 
### Error updating database.  Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'user002_sku_20240807' for key 'user_behavior_rebate_order_001.uq_biz_id'
### The error may exist in file [/Users/dongzhicheng/Desktop/Project/big-market/big-market-app/target/classes/mybatis/mapper/user_behavior_rebate_order_mapper.xml]
### The error may involve com.dzc.infrastructure.persistent.dao.IUserBehaviorRebateOrderDao.insert-Inline
### The error occurred while setting parameters
### SQL: insert into user_behavior_rebate_order_001(         user_id, order_id, behavior_type, rebate_desc, rebate_type, rebate_config, out_business_no, biz_id, create_time, update_time         ) values(         ?, ?, ?, ?, ?, ?, ?, ?, now(), now()         )
### Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'user002_sku_20240807' for key 'user_behavior_rebate_order_001.uq_biz_id'
; Duplicate entry 'user002_sku_20240807' for key 'user_behavior_rebate_order_001.uq_biz_id'; nested exception is java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'user002_sku_20240807' for key 'user_behavior_rebate_order_001.uq_biz_id'
	at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:247)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:70)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441)
	at jdk.proxy2/jdk.proxy2.$Proxy111.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:272)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:62)
	at org.apache.ibatis.binding.MapperProxy$PlainMethodInvoker.invoke(MapperProxy.java:152)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:85)
	at jdk.proxy2/jdk.proxy2.$Proxy143.insert(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:220)
	at jdk.proxy2/jdk.proxy2.$Proxy144.insert(Unknown Source)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.lambda$saveUserRebateRecord$0(BehaviorRebateRepository.java:78)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:64)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:82)
	at com.dzc.trigger.http.RaffleActivityController.calendarSignRebate(RaffleActivityController.java:191)
	at com.dzc.test.trigger.RaffleActivityControllerTest.test_calendarSignRebate(RaffleActivityControllerTest.java:62)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'user002_sku_20240807' for key 'user_behavior_rebate_order_001.uq_biz_id'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:370)
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.execute(ProxyPreparedStatement.java:44)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:47)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at jdk.proxy2/jdk.proxy2.$Proxy215.update(Unknown Source)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427)
	... 56 common frames omitted
24-08-07.21:03:19.131 [main            ] ERROR RaffleActivityController - 日历签到返利异常 userId:user002 
com.dzc.types.exception.AppException: null
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.lambda$saveUserRebateRecord$0(BehaviorRebateRepository.java:94)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:64)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:82)
	at com.dzc.trigger.http.RaffleActivityController.calendarSignRebate(RaffleActivityController.java:191)
	at com.dzc.test.trigger.RaffleActivityControllerTest.test_calendarSignRebate(RaffleActivityControllerTest.java:62)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
24-08-07.21:03:19.419 [main            ] INFO  RaffleActivityControllerTest - 测试结果：{"code":"0003","info":"唯一索引冲突"}
24-08-07.21:03:20.036 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-07.21:03:20.036 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-07.21:03:20.050 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:03:20.050 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:03:20.051 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035800050
24-08-07.21:03:20.056 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:03:28.796 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10297 ms.
24-08-07.21:03:28.800 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:03:29.060 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10555 ms.
24-08-07.21:03:29.061 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:03:29.123 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10613 ms.
24-08-07.21:03:29.123 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:03:30.630 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 10556 ms.
24-08-07.21:03:38.268 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 9094 ms.
24-08-07.21:03:38.499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 9671 ms.
24-08-07.21:03:39.944 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 10874 ms.
24-08-07.21:03:47.226 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 16473 ms.
24-08-07.21:03:54.650 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 16263 ms.
24-08-07.21:03:56.508 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 17902 ms.
24-08-07.21:04:01.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:01.663 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:02.174 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 22099 ms.
24-08-07.21:04:06.867 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:06.870 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:11.945 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:11.947 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:11.948 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:11.948 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:13.538 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 26121 ms.
24-08-07.21:04:17.109 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:17.111 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:20.080 [scheduling-1    ] ERROR LoggingProducerListener - Exception thrown when sending a message with key='null' and payload='{"data":{"bizId":"user002_integral_20240807","rebateConfig":"10","rebateType":"integral","userId":"u...' to topic send_rebate:
org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-07.21:04:20.086 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"user002_integral_20240807","rebateConfig":"10","rebateType":"integral","userId":"user002"},"id":"58580222191","timestamp":1723035755754}
org.springframework.kafka.KafkaException: Send failed; nested exception is org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:666)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$d2838f97.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-07.21:04:20.100 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: user002 topic: send_rebate
24-08-07.21:04:22.235 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:22.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:22.236 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:22.236 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:27.612 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:27.614 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:32.773 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:32.773 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:32.773 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:32.774 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:37.836 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 1 disconnected.
24-08-07.21:04:37.838 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-07.21:04:39.346 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:04:39.346 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:04:39.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:04:39.346 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:04:39.346 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:04:39.346 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:04:39.346 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:04:39.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:04:39.347 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:04:39.348 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:04:39.348 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:04:39.348 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:04:39.349 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:04:39.349 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:04:39.349 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:04:39.350 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:04:39.350 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:04:39.350 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:04:39.350 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:04:39.350 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:04:39.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:04:39.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:04:39.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:04:39.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:04:39.361 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-07.21:04:39.362 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:04:39.365 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-07.21:04:39.366 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:04:39.366 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-07.21:04:39.366 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:04:39.375 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":102,"awardTitle":"OpenAI会员卡","userId":"dzc"},"id":"87401387697","timestamp":1723035538149}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$d2838f97.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.21:04:39.375 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_award
24-08-07.21:04:39.380 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-07.21:04:39.390 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:04:39.390 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:04:39.391 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-07.21:04:39.392 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-07.21:04:39.395 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-07.21:04:39.395 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-07.21:04:39.400 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:04:39.400 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:04:39.400 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035879400
24-08-07.21:04:39.403 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":101,"awardTitle":"随机积分","userId":"user001"},"id":"61293584724","timestamp":1723035678653}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$d2838f97.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.21:04:39.403 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: user001 topic: send_award
24-08-07.21:04:39.408 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_award message:{"data":{"awardId":101,"awardTitle":"随机积分","userId":"user001"},"id":"93638410857","timestamp":1723035731018}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$d2838f97.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.21:04:39.409 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: user001 topic: send_award
24-08-07.21:04:39.415 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"user002_sku_20240807","rebateConfig":"9011","rebateType":"sku","userId":"user002"},"id":"34991446286","timestamp":1723035755752}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$d2838f97.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.21:04:39.415 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: user002 topic: send_rebate
24-08-07.21:04:39.416 [kafka-producer-network-thread | producer-2] INFO  Metadata               - [Producer clientId=producer-2] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-07.21:04:39.417 [kafka-producer-network-thread | producer-2] INFO  Metadata               - [Producer clientId=producer-2] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:05:15.635 [main            ] INFO  RaffleActivityControllerTest - Starting RaffleActivityControllerTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 55405 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-07.21:05:15.636 [main            ] INFO  RaffleActivityControllerTest - The following 1 profile is active: "dev"
24-08-07.21:05:16.651 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-07.21:05:16.654 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-07.21:05:16.683 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 19 ms. Found 0 Redis repository interfaces.
24-08-07.21:05:17.511 [main            ] INFO  Version                - Redisson 3.26.0
24-08-07.21:05:17.543 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-07.21:05:17.688 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.21:05:17.705 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-07.21:05:19.908 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-07.21:05:19.993 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:05:20.105 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:05:20.105 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:05:20.105 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035920103
24-08-07.21:05:20.116 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-07.21:05:20.123 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:05:20.129 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:05:20.129 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:05:20.129 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035920129
24-08-07.21:05:20.135 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-07.21:05:20.136 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-07.21:05:20.141 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:05:20.141 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:05:20.141 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035920141
24-08-07.21:05:20.145 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-07.21:05:20.165 [main            ] INFO  RaffleActivityControllerTest - Started RaffleActivityControllerTest in 4.938 seconds (JVM running for 6.006)
24-08-07.21:05:20.455 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-07.21:05:20.455 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-07.21:05:20.455 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-07.21:05:20.458 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:05:20.458 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:05:20.458 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:05:20.459 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:05:20.459 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:05:20.459 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-07.21:05:20.466 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-07.21:05:20.466 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-07.21:05:20.466 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-07.21:05:20.620 [main            ] INFO  RaffleActivityController - 日历签到返利开始 userId:user002
24-08-07.21:05:20.637 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:05:20.935 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:05:20.971 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:05:20.997 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:05:21.046 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，唯一索引冲突 userId: user002
org.springframework.dao.DuplicateKeyException: 
### Error updating database.  Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'user002_sku_20240807' for key 'user_behavior_rebate_order_001.uq_biz_id'
### The error may exist in file [/Users/dongzhicheng/Desktop/Project/big-market/big-market-app/target/classes/mybatis/mapper/user_behavior_rebate_order_mapper.xml]
### The error may involve com.dzc.infrastructure.persistent.dao.IUserBehaviorRebateOrderDao.insert-Inline
### The error occurred while setting parameters
### SQL: insert into user_behavior_rebate_order_001(         user_id, order_id, behavior_type, rebate_desc, rebate_type, rebate_config, out_business_no, biz_id, create_time, update_time         ) values(         ?, ?, ?, ?, ?, ?, ?, ?, now(), now()         )
### Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'user002_sku_20240807' for key 'user_behavior_rebate_order_001.uq_biz_id'
; Duplicate entry 'user002_sku_20240807' for key 'user_behavior_rebate_order_001.uq_biz_id'; nested exception is java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'user002_sku_20240807' for key 'user_behavior_rebate_order_001.uq_biz_id'
	at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:247)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:70)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441)
	at jdk.proxy2/jdk.proxy2.$Proxy111.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:272)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:62)
	at org.apache.ibatis.binding.MapperProxy$PlainMethodInvoker.invoke(MapperProxy.java:152)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:85)
	at jdk.proxy2/jdk.proxy2.$Proxy143.insert(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:220)
	at jdk.proxy2/jdk.proxy2.$Proxy144.insert(Unknown Source)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.lambda$saveUserRebateRecord$0(BehaviorRebateRepository.java:78)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:64)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:82)
	at com.dzc.trigger.http.RaffleActivityController.calendarSignRebate(RaffleActivityController.java:191)
	at com.dzc.test.trigger.RaffleActivityControllerTest.test_calendarSignRebate(RaffleActivityControllerTest.java:62)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'user002_sku_20240807' for key 'user_behavior_rebate_order_001.uq_biz_id'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:370)
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.execute(ProxyPreparedStatement.java:44)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:47)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at jdk.proxy2/jdk.proxy2.$Proxy215.update(Unknown Source)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427)
	... 56 common frames omitted
24-08-07.21:05:21.050 [main            ] ERROR RaffleActivityController - 日历签到返利异常 userId:user002 
com.dzc.types.exception.AppException: null
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.lambda$saveUserRebateRecord$0(BehaviorRebateRepository.java:94)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:64)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:82)
	at com.dzc.trigger.http.RaffleActivityController.calendarSignRebate(RaffleActivityController.java:191)
	at com.dzc.test.trigger.RaffleActivityControllerTest.test_calendarSignRebate(RaffleActivityControllerTest.java:62)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
24-08-07.21:05:21.238 [main            ] INFO  RaffleActivityControllerTest - 测试结果：{"code":"0003","info":"唯一索引冲突"}
24-08-07.21:05:25.019 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-07.21:05:25.059 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-07.21:05:25.075 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-07.21:05:25.076 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-07.21:05:25.094 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:05:25.094 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:05:25.094 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035925094
24-08-07.21:05:25.104 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-07.21:05:25.105 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:05:25.114 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_award message:{"data":{"awardId":102,"awardTitle":"OpenAI会员卡","userId":"dzc"},"id":"87401387697","timestamp":1723035538149}
24-08-07.21:05:25.128 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_award message:{"data":{"awardId":101,"awardTitle":"随机积分","userId":"user001"},"id":"61293584724","timestamp":1723035678653}
24-08-07.21:05:25.131 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_award message:{"data":{"awardId":101,"awardTitle":"随机积分","userId":"user001"},"id":"93638410857","timestamp":1723035731018}
24-08-07.21:05:30.250 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 9760 ms.
24-08-07.21:05:30.252 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:05:31.049 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10555 ms.
24-08-07.21:05:31.050 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:05:32.152 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 11672 ms.
24-08-07.21:05:32.153 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-07.21:05:34.510 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 9376 ms.
24-08-07.21:05:38.305 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 8038 ms.
24-08-07.21:05:39.677 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 8593 ms.
24-08-07.21:05:41.512 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:05:41.512 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:05:41.512 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:05:41.512 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:05:41.512 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:05:41.512 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:05:41.513 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:05:41.513 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:05:41.513 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-07.21:05:41.514 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:05:41.514 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:05:41.514 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:05:41.514 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:05:41.514 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-07.21:05:41.514 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-07.21:05:41.515 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:05:41.515 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:05:41.515 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:05:41.516 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:05:41.516 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:05:41.516 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:05:41.516 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-07.21:05:41.516 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-07.21:05:41.516 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-07.21:05:41.523 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-07.21:05:41.523 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:05:41.525 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-07.21:05:41.525 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:05:41.525 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-07.21:05:41.525 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-07.21:05:41.532 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"user002_sku_20240807","rebateConfig":"9011","rebateType":"sku","userId":"user002"},"id":"34991446286","timestamp":1723035755752}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$690345ff.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.21:05:41.534 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: user002 topic: send_rebate
24-08-07.21:05:41.535 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-07.21:05:41.543 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-07.21:05:41.543 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-07.21:05:41.546 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-07.21:05:41.546 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-07.21:05:41.546 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1723035941546
24-08-07.21:05:41.549 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"user002_integral_20240807","rebateConfig":"10","rebateType":"integral","userId":"user002"},"id":"58580222191","timestamp":1723035755754}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$690345ff.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-07.21:05:41.550 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: user002 topic: send_rebate
24-08-07.21:05:41.555 [kafka-producer-network-thread | producer-2] INFO  Metadata               - [Producer clientId=producer-2] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-07.21:05:41.555 [kafka-producer-network-thread | producer-2] INFO  Metadata               - [Producer clientId=producer-2] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-07.21:05:50.601 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-07.21:05:50.602 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
