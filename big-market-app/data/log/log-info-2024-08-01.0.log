24-08-01.20:33:53.400 [main            ] INFO  BehaviorRebateServiceTest - Starting BehaviorRebateServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 57635 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-01.20:33:53.401 [main            ] INFO  BehaviorRebateServiceTest - The following 1 profile is active: "dev"
24-08-01.20:33:54.583 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-01.20:33:54.585 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-01.20:33:54.617 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 20 ms. Found 0 Redis repository interfaces.
24-08-01.20:33:55.599 [main            ] INFO  Version                - Redisson 3.26.0
24-08-01.20:33:55.650 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-01.20:33:55.865 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.20:33:55.895 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.20:33:58.493 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-01.20:33:58.582 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.20:33:58.670 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:33:58.670 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:33:58.670 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722515638668
24-08-01.20:33:58.691 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-01.20:33:58.702 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.20:33:58.712 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:33:58.713 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:33:58.714 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722515638712
24-08-01.20:33:58.737 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-01.20:33:58.775 [main            ] INFO  BehaviorRebateServiceTest - Started BehaviorRebateServiceTest in 5.876 seconds (JVM running for 7.498)
24-08-01.20:33:59.232 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-01.20:33:59.233 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-01.20:33:59.234 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:33:59.234 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:33:59.266 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.20:33:59.267 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.20:33:59.347 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:33:59.381 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-01.20:33:59.381 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-01.20:33:59.729 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:33:59.798 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:33:59.821 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:33:59.914 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:33:59.914 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:33:59.914 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.20:33:59.914 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:33:59.914 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:33:59.914 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.20:33:59.916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:33:59.916 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:33:59.916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:33:59.916 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:34:00.193 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:34:00.287 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:34:08.364 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 9032 ms.
24-08-01.20:34:08.368 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.20:34:08.370 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:34:08.370 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:34:08.370 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.20:34:08.391 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-01.20:34:08.392 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.20:34:10.177 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10906 ms.
24-08-01.20:34:10.178 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.20:34:10.179 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:34:10.179 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:34:10.179 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.20:34:10.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-01.20:34:10.186 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.20:39:45.545 [main            ] INFO  BehaviorRebateServiceTest - Starting BehaviorRebateServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 57794 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-01.20:39:45.546 [main            ] INFO  BehaviorRebateServiceTest - The following 1 profile is active: "dev"
24-08-01.20:39:46.397 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-01.20:39:46.399 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-01.20:39:46.427 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 18 ms. Found 0 Redis repository interfaces.
24-08-01.20:39:47.371 [main            ] INFO  Version                - Redisson 3.26.0
24-08-01.20:39:47.402 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-01.20:39:47.546 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.20:39:47.560 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.20:39:49.355 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-01.20:39:49.449 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.20:39:49.533 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:39:49.534 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:39:49.534 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722515989532
24-08-01.20:39:49.545 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-01.20:39:49.551 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.20:39:49.556 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:39:49.556 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:39:49.556 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722515989556
24-08-01.20:39:49.561 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-01.20:39:49.591 [main            ] INFO  BehaviorRebateServiceTest - Started BehaviorRebateServiceTest in 4.523 seconds (JVM running for 5.823)
24-08-01.20:39:49.935 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-01.20:39:49.935 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-01.20:39:49.937 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:39:49.938 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:39:49.939 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.20:39:49.939 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.20:39:49.946 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-01.20:39:49.946 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-01.20:39:50.070 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:39:50.070 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:39:50.403 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:39:50.404 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:39:50.437 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:39:50.458 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:39:50.735 [main            ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.20:39:50.736 [main            ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.20:39:50.834 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:39:50.834 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:39:50.834 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722515990834
24-08-01.20:39:50.845 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:39:58.419 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8403 ms.
24-08-01.20:39:58.423 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.20:39:59.224 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 9273 ms.
24-08-01.20:39:59.224 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.20:40:00.954 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.20:40:00.954 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:40:06.025 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:40:06.025 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:40:06.027 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:40:06.027 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:40:06.027 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.20:40:06.027 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.20:40:06.030 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:40:06.030 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:40:06.031 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:40:06.031 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:40:06.033 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:40:06.033 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:40:06.033 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.20:40:06.033 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:40:06.033 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:40:06.034 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.20:40:06.041 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-01.20:40:06.041 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.20:40:06.043 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-01.20:40:06.043 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.20:40:06.051 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-01.20:40:06.051 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_sku_20240429","rebateConfig":"9011","rebateType":"sign","userId":"dzc"},"id":"90249014200","timestamp":1722515990443}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$57fa78de.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-01.20:40:06.054 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_rebate
24-08-01.20:40:06.055 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:40:06.055 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:40:06.055 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-01.20:40:06.056 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-01.20:40:06.056 [main            ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_sku_20240429","rebateConfig":"9011","rebateType":"sign","userId":"dzc"},"id":"90249014200","timestamp":1722515990443}
org.apache.kafka.common.KafkaException: Producer closed while send in progress
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:938)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:21)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:108)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:81)
	at com.dzc.test.domain.rebate.BehaviorRebateServiceTest.test_createOrder(BehaviorRebateServiceTest.java:32)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: org.apache.kafka.common.KafkaException: Requested metadata update after close
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:126)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 41 common frames omitted
24-08-01.20:40:06.057 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，发送MQ消息失败 userId: dzc topic: null
24-08-01.20:40:06.086 [main            ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.20:40:06.087 [main            ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.20:41:49.910 [main            ] INFO  BehaviorRebateServiceTest - Starting BehaviorRebateServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 57837 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-01.20:41:49.910 [main            ] INFO  BehaviorRebateServiceTest - The following 1 profile is active: "dev"
24-08-01.20:41:50.770 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-01.20:41:50.772 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-01.20:41:50.801 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 18 ms. Found 0 Redis repository interfaces.
24-08-01.20:41:51.596 [main            ] INFO  Version                - Redisson 3.26.0
24-08-01.20:41:51.628 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-01.20:41:51.787 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.20:41:51.802 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.20:41:53.751 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-01.20:41:53.876 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.20:41:54.007 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:41:54.007 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:41:54.007 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722516114005
24-08-01.20:41:54.027 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-01.20:41:54.038 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.20:41:54.048 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:41:54.048 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:41:54.048 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722516114048
24-08-01.20:41:54.054 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-01.20:41:54.080 [main            ] INFO  BehaviorRebateServiceTest - Started BehaviorRebateServiceTest in 4.596 seconds (JVM running for 5.867)
24-08-01.20:41:54.417 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-01.20:41:54.417 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-01.20:41:54.418 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:41:54.418 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:41:54.419 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.20:41:54.419 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.20:41:54.425 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-01.20:41:54.425 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-01.20:41:54.510 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:41:54.831 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:41:54.868 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:41:54.898 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:41:54.949 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，唯一索引冲突 userId: dzc
org.springframework.dao.DuplicateKeyException: 
### Error updating database.  Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_sku_20240429' for key 'user_behavior_rebate_order_000.uq_biz_id'
### The error may exist in file [/Users/dongzhicheng/Desktop/Project/big-market/big-market-app/target/classes/mybatis/mapper/user_behavior_rebate_order_mapper.xml]
### The error may involve com.dzc.infrastructure.persistent.dao.IUserBehaviorRebateOrderDao.insert-Inline
### The error occurred while setting parameters
### SQL: insert into user_behavior_rebate_order_000(         user_id, order_id, behavior_type, rebate_desc, rebate_type, rebate_config, biz_id, create_time, update_time         ) values(         ?, ?, ?, ?, ?, ?, ?, now(), now()         )
### Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_sku_20240429' for key 'user_behavior_rebate_order_000.uq_biz_id'
; Duplicate entry 'dzc_sku_20240429' for key 'user_behavior_rebate_order_000.uq_biz_id'; nested exception is java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_sku_20240429' for key 'user_behavior_rebate_order_000.uq_biz_id'
	at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:247)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:70)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441)
	at jdk.proxy2/jdk.proxy2.$Proxy111.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:272)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:62)
	at org.apache.ibatis.binding.MapperProxy$PlainMethodInvoker.invoke(MapperProxy.java:152)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:85)
	at jdk.proxy2/jdk.proxy2.$Proxy143.insert(Unknown Source)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.lambda$saveUserRebateRecord$0(BehaviorRebateRepository.java:77)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:64)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:81)
	at com.dzc.test.domain.rebate.BehaviorRebateServiceTest.test_createOrder(BehaviorRebateServiceTest.java:32)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_sku_20240429' for key 'user_behavior_rebate_order_000.uq_biz_id'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:370)
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.execute(ProxyPreparedStatement.java:44)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:47)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at jdk.proxy2/jdk.proxy2.$Proxy213.update(Unknown Source)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427)
	... 44 common frames omitted
24-08-01.20:41:54.975 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:41:54.975 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:41:54.975 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:41:54.975 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:41:54.975 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.20:41:54.975 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.20:41:54.977 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:41:54.977 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:41:54.977 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:41:54.977 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:41:55.049 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:41:55.077 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:41:55.112 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.20:41:55.113 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.20:41:55.157 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:41:55.158 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:41:55.158 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1722516115157
24-08-01.20:41:55.170 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:42:04.297 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 9797 ms.
24-08-01.20:42:04.302 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.20:42:04.305 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:42:04.305 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:42:04.305 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.20:42:04.321 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-01.20:42:04.325 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.20:42:04.602 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 9399 ms.
24-08-01.20:42:05.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10729 ms.
24-08-01.20:42:05.203 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.20:42:05.205 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:42:05.205 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:42:05.205 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.20:42:05.210 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-01.20:42:05.211 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.20:42:05.223 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_integral_20240429","rebateConfig":"10","rebateType":"sign","userId":"dzc"},"id":"53983565667","timestamp":1722515990444}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$57fa78de.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-01.20:42:05.227 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-01.20:42:05.229 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_rebate
24-08-01.20:42:05.230 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:42:05.230 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:42:05.230 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-01.20:42:05.230 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-01.20:46:55.985 [main            ] INFO  BehaviorRebateServiceTest - Starting BehaviorRebateServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 57926 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-01.20:46:55.986 [main            ] INFO  BehaviorRebateServiceTest - The following 1 profile is active: "dev"
24-08-01.20:46:57.122 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-01.20:46:57.125 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-01.20:46:57.156 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 20 ms. Found 0 Redis repository interfaces.
24-08-01.20:46:57.957 [main            ] INFO  Version                - Redisson 3.26.0
24-08-01.20:46:57.984 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-01.20:46:58.115 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.20:46:58.127 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.20:46:59.888 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-01.20:46:59.976 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.20:47:00.182 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:47:00.183 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:47:00.183 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722516420179
24-08-01.20:47:00.220 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-01.20:47:00.233 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.20:47:00.242 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:47:00.242 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:47:00.242 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722516420242
24-08-01.20:47:00.249 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-01.20:47:00.283 [main            ] INFO  BehaviorRebateServiceTest - Started BehaviorRebateServiceTest in 4.732 seconds (JVM running for 5.975)
24-08-01.20:47:00.756 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-01.20:47:00.756 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-01.20:47:00.759 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:47:00.759 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:47:00.761 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.20:47:00.761 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.20:47:00.769 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-01.20:47:00.769 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-01.20:47:00.865 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:47:01.224 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:47:01.259 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:47:01.282 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:47:01.493 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，唯一索引冲突 userId: dzc
org.springframework.dao.DuplicateKeyException: 
### Error updating database.  Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_integral_20240429' for key 'user_behavior_rebate_order_000.uq_biz_id'
### The error may exist in file [/Users/dongzhicheng/Desktop/Project/big-market/big-market-app/target/classes/mybatis/mapper/user_behavior_rebate_order_mapper.xml]
### The error may involve com.dzc.infrastructure.persistent.dao.IUserBehaviorRebateOrderDao.insert-Inline
### The error occurred while setting parameters
### SQL: insert into user_behavior_rebate_order_000(         user_id, order_id, behavior_type, rebate_desc, rebate_type, rebate_config, biz_id, create_time, update_time         ) values(         ?, ?, ?, ?, ?, ?, ?, now(), now()         )
### Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_integral_20240429' for key 'user_behavior_rebate_order_000.uq_biz_id'
; Duplicate entry 'dzc_integral_20240429' for key 'user_behavior_rebate_order_000.uq_biz_id'; nested exception is java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_integral_20240429' for key 'user_behavior_rebate_order_000.uq_biz_id'
	at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:247)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:70)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441)
	at jdk.proxy2/jdk.proxy2.$Proxy111.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:272)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:62)
	at org.apache.ibatis.binding.MapperProxy$PlainMethodInvoker.invoke(MapperProxy.java:152)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:85)
	at jdk.proxy2/jdk.proxy2.$Proxy143.insert(Unknown Source)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.lambda$saveUserRebateRecord$0(BehaviorRebateRepository.java:77)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:64)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:81)
	at com.dzc.test.domain.rebate.BehaviorRebateServiceTest.test_createOrder(BehaviorRebateServiceTest.java:32)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_integral_20240429' for key 'user_behavior_rebate_order_000.uq_biz_id'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:370)
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.execute(ProxyPreparedStatement.java:44)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:47)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at jdk.proxy2/jdk.proxy2.$Proxy213.update(Unknown Source)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427)
	... 44 common frames omitted
24-08-01.20:47:01.526 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:47:01.526 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:47:01.526 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.20:47:01.526 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:47:01.526 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:47:01.526 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.20:47:01.527 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:47:01.527 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:47:01.527 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:47:01.527 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:47:05.041 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.20:47:05.043 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.20:47:05.066 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:47:05.067 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:47:05.067 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1722516425066
24-08-01.20:47:05.072 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:47:05.790 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 2147483646 disconnected.
24-08-01.20:47:05.791 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 2147483646 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:47:05.793 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.20:47:05.794 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:47:05.794 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:47:05.794 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.20:47:05.801 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-01.20:47:05.802 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.20:47:09.629 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8842 ms.
24-08-01.20:47:09.630 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.20:47:09.633 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:47:09.633 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:47:09.633 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.20:47:09.637 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-01.20:47:09.637 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.20:47:09.646 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_sku_20240429","rebateConfig":"9011","rebateType":"sign","userId":"dzc"},"id":"90249014200","timestamp":1722515990443}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$151c34f3.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-01.20:47:09.649 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-01.20:47:09.651 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_rebate
24-08-01.20:47:09.652 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:47:09.652 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:47:09.652 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-01.20:47:09.652 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-01.20:47:09.670 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.20:47:09.670 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.20:47:09.675 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:47:09.675 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:47:09.675 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1722516429675
24-08-01.20:52:43.804 [main            ] INFO  BehaviorRebateServiceTest - Starting BehaviorRebateServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 58038 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-01.20:52:43.806 [main            ] INFO  BehaviorRebateServiceTest - The following 1 profile is active: "dev"
24-08-01.20:52:44.905 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-01.20:52:44.908 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-01.20:52:45.015 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 76 ms. Found 0 Redis repository interfaces.
24-08-01.20:52:46.010 [main            ] INFO  Version                - Redisson 3.26.0
24-08-01.20:52:46.040 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-01.20:52:46.203 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.20:52:46.222 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.20:52:48.150 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-01.20:52:48.246 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.20:52:48.351 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:52:48.351 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:52:48.351 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722516768350
24-08-01.20:52:48.364 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-01.20:52:48.372 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.20:52:48.378 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:52:48.378 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:52:48.378 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722516768378
24-08-01.20:52:48.383 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-01.20:52:48.405 [main            ] INFO  BehaviorRebateServiceTest - Started BehaviorRebateServiceTest in 5.005 seconds (JVM running for 6.889)
24-08-01.20:52:48.780 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-01.20:52:48.780 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-01.20:52:48.782 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:52:48.782 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:52:48.783 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.20:52:48.784 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.20:52:48.801 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-01.20:52:48.801 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-01.20:52:48.877 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:52:49.257 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:52:49.307 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.20:52:49.329 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.20:52:49.548 [main            ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.20:52:49.549 [main            ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.20:52:49.601 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.20:52:49.601 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.20:52:49.602 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722516769601
24-08-01.20:52:49.610 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.20:52:58.516 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 9684 ms.
24-08-01.20:52:58.521 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.20:52:59.098 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10249 ms.
24-08-01.20:52:59.099 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.20:52:59.337 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 9717 ms.
24-08-01.20:53:07.071 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 8513 ms.
24-08-01.20:53:10.449 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:53:10.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:10.455 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.20:53:10.455 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:23.229 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:53:23.230 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.20:53:23.232 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:23.233 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:23.243 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:53:23.245 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:33.712 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:53:33.712 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:53:33.715 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.20:53:33.718 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:33.718 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:33.718 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:44.334 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:53:44.334 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:53:44.334 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.20:53:44.336 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:44.336 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:44.336 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:49.642 [main            ] ERROR LoggingProducerListener - Exception thrown when sending a message with key='null' and payload='{"data":{"bizId":"dzc_sku_20240429","rebateConfig":"9011","rebateType":"sign","userId":"dzc"},"id":"...' to topic send_rebate:
org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-01.20:53:49.647 [main            ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_sku_20240429","rebateConfig":"9011","rebateType":"sign","userId":"dzc"},"id":"56617956332","timestamp":1722516769304}
org.springframework.kafka.KafkaException: Send failed; nested exception is org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:666)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:21)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:108)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:81)
	at com.dzc.test.domain.rebate.BehaviorRebateServiceTest.test_createOrder(BehaviorRebateServiceTest.java:32)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-01.20:53:49.649 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，发送MQ消息失败 userId: dzc topic: null
24-08-01.20:53:50.020 [scheduling-1    ] ERROR LoggingProducerListener - Exception thrown when sending a message with key='null' and payload='{"data":{"bizId":"dzc_sku_20240429","rebateConfig":"9011","rebateType":"sign","userId":"dzc"},"id":"...' to topic send_rebate:
org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-01.20:53:50.023 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_sku_20240429","rebateConfig":"9011","rebateType":"sign","userId":"dzc"},"id":"90249014200","timestamp":1722515990443}
org.springframework.kafka.KafkaException: Send failed; nested exception is org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:666)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$57fa78de.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-01.20:53:50.040 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_rebate
24-08-01.20:53:55.260 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:53:55.260 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:53:55.260 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.20:53:55.263 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:55.263 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:53:55.263 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:06.485 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.20:54:06.488 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:06.495 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:54:06.495 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:54:06.496 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:06.496 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:17.754 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:54:17.754 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.20:54:17.754 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:54:17.755 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:17.755 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:17.756 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:29.211 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.20:54:29.211 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:54:29.211 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:54:29.213 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:29.213 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:29.213 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:40.616 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.20:54:40.616 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:54:40.616 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:40.616 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:40.616 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-01.20:54:40.617 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.20:54:49.706 [main            ] ERROR LoggingProducerListener - Exception thrown when sending a message with key='null' and payload='{"data":{"bizId":"dzc_integral_20240429","rebateConfig":"10","rebateType":"sign","userId":"dzc"},"id...' to topic send_rebate:
org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-01.20:54:49.710 [main            ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_integral_20240429","rebateConfig":"10","rebateType":"sign","userId":"dzc"},"id":"43702406222","timestamp":1722516769305}
org.springframework.kafka.KafkaException: Send failed; nested exception is org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:666)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:21)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:108)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:81)
	at com.dzc.test.domain.rebate.BehaviorRebateServiceTest.test_createOrder(BehaviorRebateServiceTest.java:32)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-01.20:54:49.712 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，发送MQ消息失败 userId: dzc topic: null
24-08-01.20:54:49.761 [main            ] INFO  BehaviorRebateServiceTest - 请求参数：{"behaviorTypeVO":"SIGN","outBusinessNo":"20240429","userId":"dzc"}
24-08-01.20:54:49.771 [main            ] INFO  BehaviorRebateServiceTest - 测试结果：["768803499572","484688931601"]
24-08-01.20:54:49.798 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:54:49.798 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:54:49.798 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:54:49.798 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:54:49.798 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.20:54:49.798 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.20:54:49.799 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:54:49.799 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:54:49.799 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.20:54:49.799 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.20:54:49.802 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:54:49.803 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:54:49.803 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:54:49.803 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:54:49.803 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.20:54:49.803 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.20:54:49.815 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-01.20:54:49.817 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.20:54:49.819 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-01.20:54:49.819 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.20:54:49.824 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_integral_20240429","rebateConfig":"10","rebateType":"sign","userId":"dzc"},"id":"53983565667","timestamp":1722515990444}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$57fa78de.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-01.20:54:49.825 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_rebate
24-08-01.20:54:49.827 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-01.20:54:49.829 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-01.20:54:49.829 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.20:54:49.829 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-01.20:54:49.829 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-01.22:18:36.343 [main            ] INFO  BehaviorRebateServiceTest - Starting BehaviorRebateServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 59949 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-01.22:18:36.344 [main            ] INFO  BehaviorRebateServiceTest - The following 1 profile is active: "dev"
24-08-01.22:18:37.216 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-01.22:18:37.217 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-01.22:18:37.244 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 16 ms. Found 0 Redis repository interfaces.
24-08-01.22:18:38.025 [main            ] INFO  Version                - Redisson 3.26.0
24-08-01.22:18:38.053 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-01.22:18:38.195 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.22:18:38.211 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.22:18:39.996 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-01.22:18:40.089 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:18:40.189 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:18:40.189 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:18:40.189 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722521920187
24-08-01.22:18:40.202 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-01.22:18:40.211 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:18:40.221 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:18:40.221 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:18:40.221 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722521920220
24-08-01.22:18:40.228 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-01.22:18:40.231 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:18:40.237 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:18:40.237 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:18:40.238 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722521920237
24-08-01.22:18:40.242 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-01.22:18:40.277 [main            ] INFO  BehaviorRebateServiceTest - Started BehaviorRebateServiceTest in 4.505 seconds (JVM running for 5.677)
24-08-01.22:18:40.728 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-01.22:18:40.728 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-01.22:18:40.734 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:18:40.735 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:18:40.755 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:18:40.755 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:18:40.875 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-01.22:18:40.877 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-01.22:18:41.071 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:18:41.230 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Error while fetching metadata with correlation id 2 : {send_rebate=LEADER_NOT_AVAILABLE}
24-08-01.22:18:41.230 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:18:41.231 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:18:41.240 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-01.22:18:41.678 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:18:41.832 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:18:41.857 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:18:42.136 [main            ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.22:18:42.136 [main            ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.22:18:42.196 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:18:42.196 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:18:42.196 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722521922196
24-08-01.22:18:42.208 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:18:45.017 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:18:45.034 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:18:50.510 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 9130 ms.
24-08-01.22:18:51.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10251 ms.
24-08-01.22:18:51.041 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:18:51.269 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 2147483646 disconnected.
24-08-01.22:18:51.269 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 2147483646 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:18:51.269 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:18:51.330 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10558 ms.
24-08-01.22:18:51.330 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:18:52.564 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 10304 ms.
24-08-01.22:19:01.459 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 10370 ms.
24-08-01.22:19:01.721 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 1 disconnected.
24-08-01.22:19:01.722 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:01.722 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.22:19:01.722 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:02.674 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 11326 ms.
24-08-01.22:19:12.112 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.22:19:12.114 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:17.441 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 1 disconnected.
24-08-01.22:19:17.443 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:19.834 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 18268 ms.
24-08-01.22:19:22.728 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 1 disconnected.
24-08-01.22:19:22.732 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:22.734 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.22:19:22.734 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:23.566 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 20753 ms.
24-08-01.22:19:33.229 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.22:19:33.227 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 1 disconnected.
24-08-01.22:19:33.233 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:33.233 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:38.651 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:38.651 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:38.652 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:38.652 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:38.651 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:38.652 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:38.652 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:19:38.652 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:19:38.652 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:19:38.653 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:38.653 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:38.653 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:38.653 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:38.653 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:38.653 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:38.655 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:19:38.655 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:19:38.655 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:19:38.655 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:19:38.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:19:38.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:19:38.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:19:38.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:19:38.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:19:38.670 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-01.22:19:38.671 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:19:38.675 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-01.22:19:38.675 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:19:38.678 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-01.22:19:38.679 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:19:38.690 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-01.22:19:38.689 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_sku_20240429","rebateConfig":"9011","rebateType":"sign","userId":"dzc"},"id":"90249014200","timestamp":1722515990443}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$4a3b3a1c.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db02(SendMessageTaskJob.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-01.22:19:38.694 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: dzc topic: send_rebate
24-08-01.22:19:38.695 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:19:38.695 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:19:38.695 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-01.22:19:38.695 [main            ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"xiaofuge_sku_2024042906","rebateConfig":"9011","rebateType":"sku","userId":"xiaofuge"},"id":"67817238123","timestamp":1722521921829}
org.apache.kafka.common.KafkaException: Producer closed while send in progress
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:938)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:21)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:108)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:81)
	at com.dzc.test.domain.rebate.BehaviorRebateServiceTest.test_createOrder(BehaviorRebateServiceTest.java:43)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: org.apache.kafka.common.KafkaException: Requested metadata update after close
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:126)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 42 common frames omitted
24-08-01.22:19:38.696 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，发送MQ消息失败 userId: xiaofuge topic: null
24-08-01.22:19:38.696 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-01.22:19:42.604 [main            ] INFO  BehaviorRebateServiceTest - Starting BehaviorRebateServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 59984 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-01.22:19:42.605 [main            ] INFO  BehaviorRebateServiceTest - The following 1 profile is active: "dev"
24-08-01.22:19:43.431 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-01.22:19:43.433 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-01.22:19:43.463 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 18 ms. Found 0 Redis repository interfaces.
24-08-01.22:19:44.311 [main            ] INFO  Version                - Redisson 3.26.0
24-08-01.22:19:44.338 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-01.22:19:44.467 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.22:19:44.481 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.22:19:46.240 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-01.22:19:46.335 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:19:46.431 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:19:46.431 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:19:46.431 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722521986430
24-08-01.22:19:46.444 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-01.22:19:46.452 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:19:46.457 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:19:46.457 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:19:46.457 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722521986457
24-08-01.22:19:46.461 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-01.22:19:46.464 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:19:46.469 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:19:46.469 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:19:46.469 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722521986469
24-08-01.22:19:46.474 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-01.22:19:46.493 [main            ] INFO  BehaviorRebateServiceTest - Started BehaviorRebateServiceTest in 4.349 seconds (JVM running for 5.794)
24-08-01.22:19:46.876 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-01.22:19:46.876 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-01.22:19:46.876 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-01.22:19:46.881 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:19:46.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:19:46.882 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:19:46.883 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:19:46.883 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:19:46.883 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:19:46.890 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-01.22:19:46.890 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-01.22:19:46.890 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-01.22:19:47.061 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:19:47.452 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:19:47.553 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:19:47.578 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:19:47.647 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，唯一索引冲突 userId: xiaofuge
org.springframework.dao.DuplicateKeyException: 
### Error updating database.  Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'xiaofuge_sku_2024042906' for key 'user_behavior_rebate_order_001.uq_biz_id'
### The error may exist in file [/Users/dongzhicheng/Desktop/Project/big-market/big-market-app/target/classes/mybatis/mapper/user_behavior_rebate_order_mapper.xml]
### The error may involve com.dzc.infrastructure.persistent.dao.IUserBehaviorRebateOrderDao.insert-Inline
### The error occurred while setting parameters
### SQL: insert into user_behavior_rebate_order_001(         user_id, order_id, behavior_type, rebate_desc, rebate_type, rebate_config, biz_id, create_time, update_time         ) values(         ?, ?, ?, ?, ?, ?, ?, now(), now()         )
### Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'xiaofuge_sku_2024042906' for key 'user_behavior_rebate_order_001.uq_biz_id'
; Duplicate entry 'xiaofuge_sku_2024042906' for key 'user_behavior_rebate_order_001.uq_biz_id'; nested exception is java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'xiaofuge_sku_2024042906' for key 'user_behavior_rebate_order_001.uq_biz_id'
	at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:247)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:70)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441)
	at jdk.proxy2/jdk.proxy2.$Proxy112.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:272)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:62)
	at org.apache.ibatis.binding.MapperProxy$PlainMethodInvoker.invoke(MapperProxy.java:152)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:85)
	at jdk.proxy2/jdk.proxy2.$Proxy142.insert(Unknown Source)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.lambda$saveUserRebateRecord$0(BehaviorRebateRepository.java:77)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:64)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:81)
	at com.dzc.test.domain.rebate.BehaviorRebateServiceTest.test_createOrder(BehaviorRebateServiceTest.java:43)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'xiaofuge_sku_2024042906' for key 'user_behavior_rebate_order_001.uq_biz_id'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:370)
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.execute(ProxyPreparedStatement.java:44)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:47)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at jdk.proxy2/jdk.proxy2.$Proxy214.update(Unknown Source)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427)
	... 45 common frames omitted
24-08-01.22:19:47.689 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:47.690 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:47.690 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:47.690 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:19:47.689 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:47.693 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:47.694 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:19:47.690 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:47.696 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:19:47.699 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:47.699 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:47.699 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:47.699 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:47.699 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:19:47.699 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:19:50.027 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.22:19:50.028 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.22:19:50.052 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:19:50.052 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:19:50.052 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1722521990052
24-08-01.22:19:50.058 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:19:57.095 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 2147483646 disconnected.
24-08-01.22:19:57.097 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 2147483646 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:57.097 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 2147483646 disconnected.
24-08-01.22:19:57.098 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 2147483646 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:57.098 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 2147483646 disconnected.
24-08-01.22:19:57.098 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 2147483646 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:19:57.099 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:19:57.099 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:19:57.099 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:19:57.116 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:19:57.116 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:19:57.117 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:19:57.117 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:19:57.117 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:19:57.117 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:19:57.117 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:19:57.117 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:19:57.117 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:19:57.142 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-01.22:19:57.145 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:19:57.146 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-01.22:19:57.146 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:19:57.147 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-01.22:19:57.147 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:19:57.153 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"xiaofuge_integral_2024042906","rebateConfig":"10","rebateType":"integral","userId":"xiaofuge"},"id":"25352869675","timestamp":1722521921830}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$dbdb1a2c.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db01(SendMessageTaskJob.java:37)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-01.22:19:57.156 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-01.22:19:57.157 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: xiaofuge topic: send_rebate
24-08-01.22:19:57.161 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:19:57.162 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:19:57.162 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-01.22:19:57.162 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-01.22:19:57.182 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.22:19:57.183 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.22:21:13.470 [main            ] INFO  BehaviorRebateServiceTest - Starting BehaviorRebateServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 60021 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-01.22:21:13.471 [main            ] INFO  BehaviorRebateServiceTest - The following 1 profile is active: "dev"
24-08-01.22:21:14.487 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-01.22:21:14.506 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-01.22:21:14.559 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 31 ms. Found 0 Redis repository interfaces.
24-08-01.22:21:16.176 [main            ] INFO  Version                - Redisson 3.26.0
24-08-01.22:21:16.696 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-01.22:21:17.071 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.22:21:17.094 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.22:21:19.190 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-01.22:21:19.279 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:21:19.377 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:21:19.377 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:21:19.377 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522079376
24-08-01.22:21:19.389 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-01.22:21:19.395 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:21:19.400 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:21:19.400 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:21:19.400 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522079400
24-08-01.22:21:19.406 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-01.22:21:19.408 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:21:19.414 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:21:19.414 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:21:19.414 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522079414
24-08-01.22:21:19.419 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-01.22:21:19.438 [main            ] INFO  BehaviorRebateServiceTest - Started BehaviorRebateServiceTest in 6.386 seconds (JVM running for 7.334)
24-08-01.22:21:19.848 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-01.22:21:19.848 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-01.22:21:19.848 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-01.22:21:19.851 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:21:19.851 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:21:19.851 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:21:19.852 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:21:19.852 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:21:19.852 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:21:19.859 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-01.22:21:19.859 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-01.22:21:19.860 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-01.22:21:19.996 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:21:20.036 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:21:20.536 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:21:20.557 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:21:20.605 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.22:21:20.605 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.22:21:20.638 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:21:20.638 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:21:20.638 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522080638
24-08-01.22:21:20.648 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:21:20.695 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:21:20.729 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:21:29.932 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 9259 ms.
24-08-01.22:21:30.018 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10114 ms.
24-08-01.22:21:30.019 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:21:30.234 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10357 ms.
24-08-01.22:21:30.235 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:21:31.231 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 11365 ms.
24-08-01.22:21:31.232 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:21:38.805 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 8754 ms.
24-08-01.22:21:39.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 9198 ms.
24-08-01.22:21:41.277 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 10028 ms.
24-08-01.22:21:41.279 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.22:21:41.279 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:22:00.357 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 20762 ms.
24-08-01.22:22:01.631 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 22675 ms.
24-08-01.22:22:03.113 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 21702 ms.
24-08-01.22:22:11.330 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 29902 ms.
24-08-01.22:22:19.301 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.22:22:19.305 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:22:19.307 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.22:22:19.307 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:22:20.699 [scheduling-1    ] ERROR LoggingProducerListener - Exception thrown when sending a message with key='null' and payload='{"data":{"bizId":"xiaofuge_sku_2024042906","rebateConfig":"9011","rebateType":"sku","userId":"xiaofu...' to topic send_rebate:
org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-01.22:22:20.717 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"xiaofuge_sku_2024042906","rebateConfig":"9011","rebateType":"sku","userId":"xiaofuge"},"id":"67817238123","timestamp":1722521921829}
org.springframework.kafka.KafkaException: Send failed; nested exception is org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:666)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$ab22cf6a.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db01(SendMessageTaskJob.java:37)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-01.22:22:20.746 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: xiaofuge topic: send_rebate
24-08-01.22:22:21.125 [main            ] ERROR LoggingProducerListener - Exception thrown when sending a message with key='null' and payload='{"data":{"bizId":"dzc_sku_2024042906","rebateConfig":"9011","rebateType":"sku","userId":"dzc"},"id":...' to topic send_rebate:
org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-01.22:22:21.126 [main            ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_sku_2024042906","rebateConfig":"9011","rebateType":"sku","userId":"dzc"},"id":"01837031268","timestamp":1722522080688}
org.springframework.kafka.KafkaException: Send failed; nested exception is org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:666)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:21)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:108)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:81)
	at com.dzc.test.domain.rebate.BehaviorRebateServiceTest.test_createOrder(BehaviorRebateServiceTest.java:43)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: org.apache.kafka.common.errors.TimeoutException: Topic send_rebate not present in metadata after 60000 ms.
24-08-01.22:22:21.127 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，发送MQ消息失败 userId: dzc topic: null
24-08-01.22:22:24.503 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 1 disconnected.
24-08-01.22:22:24.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:22:30.770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 29013 ms.
24-08-01.22:22:34.301 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:34.301 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:34.301 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:34.301 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:34.301 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:34.301 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:34.301 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:22:34.302 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:22:34.302 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:22:34.303 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:34.303 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:34.303 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:34.303 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:34.303 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:34.303 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:34.304 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:22:34.305 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:22:34.305 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:22:34.305 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:22:34.305 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:22:34.305 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:22:34.306 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:22:34.306 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:22:34.306 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:22:34.328 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-01.22:22:34.328 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-01.22:22:34.328 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-01.22:22:34.329 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:22:34.329 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:22:34.329 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:22:34.336 [scheduling-1    ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"xiaofuge_integral_2024042906","rebateConfig":"10","rebateType":"integral","userId":"xiaofuge"},"id":"25352869675","timestamp":1722521921830}
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1030)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:31)
	at com.dzc.infrastructure.persistent.repository.TaskRepository.sendMessage(TaskRepository.java:39)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$FastClassBySpringCGLIB$$63670079.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at com.dzc.infrastructure.persistent.repository.TaskRepository$$EnhancerBySpringCGLIB$$ab22cf6a.sendMessage(<generated>)
	at com.dzc.domain.task.service.TaskService.sendMessage(TaskService.java:23)
	at com.dzc.trigger.job.SendMessageTaskJob.exec_db01(SendMessageTaskJob.java:37)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: java.lang.InterruptedException: null
	at java.base/java.lang.Object.wait(Native Method)
	at org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:55)
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:119)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 32 common frames omitted
24-08-01.22:22:34.337 [scheduling-1    ] ERROR SendMessageTaskJob     - 定时任务，发送MQ消息失败 userId: xiaofuge topic: send_rebate
24-08-01.22:22:34.338 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-01.22:22:34.339 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:22:34.340 [SpringApplicationShutdownHook] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:22:34.340 [SpringApplicationShutdownHook] INFO  Metrics                - Metrics reporters closed
24-08-01.22:22:34.340 [SpringApplicationShutdownHook] INFO  AppInfoParser          - App info kafka.producer for producer-1 unregistered
24-08-01.22:22:34.340 [main            ] ERROR EventPublisher         - 发送MQ消息失败 topic:send_rebate message:{"data":{"bizId":"dzc_integral_2024042906","rebateConfig":"10","rebateType":"integral","userId":"dzc"},"id":"22100895218","timestamp":1722522080690}
org.apache.kafka.common.KafkaException: Producer closed while send in progress
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:938)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1087)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:655)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:403)
	at com.dzc.infrastructure.event.EventPublisher.publish(EventPublisher.java:21)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:108)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:81)
	at com.dzc.test.domain.rebate.BehaviorRebateServiceTest.test_createOrder(BehaviorRebateServiceTest.java:43)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: org.apache.kafka.common.KafkaException: Requested metadata update after close
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:126)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1088)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:935)
	... 42 common frames omitted
24-08-01.22:22:34.341 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，发送MQ消息失败 userId: dzc topic: null
24-08-01.22:22:34.351 [main            ] INFO  BehaviorRebateServiceTest - 请求参数：{"behaviorTypeVO":"SIGN","outBusinessNo":"2024042906","userId":"dzc"}
24-08-01.22:22:34.357 [main            ] INFO  BehaviorRebateServiceTest - 测试结果：["558443741671","598789868838"]
24-08-01.22:22:36.164 [main            ] INFO  BehaviorRebateServiceTest - Starting BehaviorRebateServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 60079 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-01.22:22:36.165 [main            ] INFO  BehaviorRebateServiceTest - The following 1 profile is active: "dev"
24-08-01.22:22:36.734 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-01.22:22:36.736 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-01.22:22:36.756 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 12 ms. Found 0 Redis repository interfaces.
24-08-01.22:22:37.361 [main            ] INFO  Version                - Redisson 3.26.0
24-08-01.22:22:37.382 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-01.22:22:37.482 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.22:22:37.499 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.22:22:38.709 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-01.22:22:38.778 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:22:38.845 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:22:38.846 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:22:38.846 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522158845
24-08-01.22:22:38.854 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-01.22:22:38.858 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:22:38.861 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:22:38.861 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:22:38.861 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522158861
24-08-01.22:22:38.864 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-01.22:22:38.865 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:22:38.868 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:22:38.868 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:22:38.868 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522158868
24-08-01.22:22:38.870 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-01.22:22:38.881 [main            ] INFO  BehaviorRebateServiceTest - Started BehaviorRebateServiceTest in 2.997 seconds (JVM running for 3.728)
24-08-01.22:22:39.062 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-01.22:22:39.062 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-01.22:22:39.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-01.22:22:39.063 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:22:39.063 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:22:39.063 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:22:39.065 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:22:39.065 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:22:39.066 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:22:39.085 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-01.22:22:39.086 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-01.22:22:39.087 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-01.22:22:39.136 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:22:39.366 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:22:39.440 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:22:39.455 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:22:39.487 [main            ] ERROR BehaviorRebateRepository - 写入返利记录，唯一索引冲突 userId: dzc
org.springframework.dao.DuplicateKeyException: 
### Error updating database.  Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_sku_2024042906' for key 'user_behavior_rebate_order_000.uq_biz_id'
### The error may exist in file [/Users/dongzhicheng/Desktop/Project/big-market/big-market-app/target/classes/mybatis/mapper/user_behavior_rebate_order_mapper.xml]
### The error may involve com.dzc.infrastructure.persistent.dao.IUserBehaviorRebateOrderDao.insert-Inline
### The error occurred while setting parameters
### SQL: insert into user_behavior_rebate_order_000(         user_id, order_id, behavior_type, rebate_desc, rebate_type, rebate_config, biz_id, create_time, update_time         ) values(         ?, ?, ?, ?, ?, ?, ?, now(), now()         )
### Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_sku_2024042906' for key 'user_behavior_rebate_order_000.uq_biz_id'
; Duplicate entry 'dzc_sku_2024042906' for key 'user_behavior_rebate_order_000.uq_biz_id'; nested exception is java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_sku_2024042906' for key 'user_behavior_rebate_order_000.uq_biz_id'
	at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:247)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:70)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441)
	at jdk.proxy2/jdk.proxy2.$Proxy112.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:272)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:62)
	at org.apache.ibatis.binding.MapperProxy$PlainMethodInvoker.invoke(MapperProxy.java:152)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:85)
	at jdk.proxy2/jdk.proxy2.$Proxy142.insert(Unknown Source)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.lambda$saveUserRebateRecord$0(BehaviorRebateRepository.java:77)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
	at com.dzc.infrastructure.persistent.repository.BehaviorRebateRepository.saveUserRebateRecord(BehaviorRebateRepository.java:64)
	at com.dzc.domain.rebate.service.BehaviorRebateService.createOrder(BehaviorRebateService.java:81)
	at com.dzc.test.domain.rebate.BehaviorRebateServiceTest.test_createOrder(BehaviorRebateServiceTest.java:43)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74)
	at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry 'dzc_sku_2024042906' for key 'user_behavior_rebate_order_000.uq_biz_id'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:370)
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.execute(ProxyPreparedStatement.java:44)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:47)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at jdk.proxy2/jdk.proxy2.$Proxy214.update(Unknown Source)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427)
	... 45 common frames omitted
24-08-01.22:22:39.503 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:39.503 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:39.504 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:39.504 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:39.504 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:22:39.504 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:39.504 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:22:39.504 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:39.504 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:22:39.505 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:39.505 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:39.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:39.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:22:39.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:39.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:22:40.021 [scheduling-1    ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.22:22:40.021 [scheduling-1    ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.22:22:40.041 [scheduling-1    ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:22:40.041 [scheduling-1    ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:22:40.041 [scheduling-1    ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522160041
24-08-01.22:22:40.048 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-01.22:22:40.048 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:22:40.056 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_rebate message:{"data":{"bizId":"dzc_sku_20240429","rebateConfig":"9011","rebateType":"sign","userId":"dzc"},"id":"90249014200","timestamp":1722515990443}
24-08-01.22:22:40.067 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_rebate message:{"data":{"bizId":"dzc_integral_20240429","rebateConfig":"10","rebateType":"sign","userId":"dzc"},"id":"53983565667","timestamp":1722515990444}
24-08-01.22:22:40.069 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_rebate message:{"data":{"bizId":"dzc_sku_20240429","rebateConfig":"9011","rebateType":"sign","userId":"dzc"},"id":"56617956332","timestamp":1722516769304}
24-08-01.22:22:40.071 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_rebate message:{"data":{"bizId":"dzc_integral_20240429","rebateConfig":"10","rebateType":"sign","userId":"dzc"},"id":"43702406222","timestamp":1722516769305}
24-08-01.22:22:40.072 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_rebate message:{"data":{"bizId":"dzc_sku_2024042906","rebateConfig":"9011","rebateType":"sku","userId":"dzc"},"id":"01837031268","timestamp":1722522080688}
24-08-01.22:22:40.074 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_rebate message:{"data":{"bizId":"dzc_integral_2024042906","rebateConfig":"10","rebateType":"integral","userId":"dzc"},"id":"22100895218","timestamp":1722522080690}
24-08-01.22:22:40.082 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:22:40.093 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:22:40.095 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_rebate message:{"data":{"bizId":"xiaofuge_sku_2024042906","rebateConfig":"9011","rebateType":"sku","userId":"xiaofuge"},"id":"67817238123","timestamp":1722521921829}
24-08-01.22:22:40.097 [scheduling-1    ] INFO  EventPublisher         - 发送MQ消息 topic:send_rebate message:{"data":{"bizId":"xiaofuge_integral_2024042906","rebateConfig":"10","rebateType":"integral","userId":"xiaofuge"},"id":"25352869675","timestamp":1722521921830}
24-08-01.22:22:47.601 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8464 ms.
24-08-01.22:22:47.606 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:22:47.608 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:22:47.608 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:22:47.608 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:22:47.617 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-01.22:22:47.619 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:22:48.707 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 9580 ms.
24-08-01.22:22:48.708 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:22:48.709 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:22:48.709 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:22:48.709 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:22:48.713 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-01.22:22:48.714 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:22:49.830 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 10690 ms.
24-08-01.22:22:49.833 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:22:49.835 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:22:49.835 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:22:49.835 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:22:49.841 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-01.22:22:49.842 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:22:49.880 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
24-08-01.22:23:01.393 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 11508 ms.
24-08-01.22:23:09.471 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Node 1 disconnected.
24-08-01.22:23:09.473 [kafka-producer-network-thread | producer-1] WARN  NetworkClient          - [Producer clientId=producer-1] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:23:15.643 [main            ] INFO  BehaviorRebateServiceTest - Starting BehaviorRebateServiceTest using Java 17.0.10 on dongzhichengdeMacBook-Air.local with PID 60199 (started by dongzhicheng in /Users/dongzhicheng/Desktop/Project/big-market/big-market-app)
24-08-01.22:23:15.644 [main            ] INFO  BehaviorRebateServiceTest - The following 1 profile is active: "dev"
24-08-01.22:23:16.260 [main            ] INFO  RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
24-08-01.22:23:16.262 [main            ] INFO  RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
24-08-01.22:23:16.286 [main            ] INFO  RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 16 ms. Found 0 Redis repository interfaces.
24-08-01.22:23:16.975 [main            ] INFO  Version                - Redisson 3.26.0
24-08-01.22:23:16.996 [main            ] WARN  DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS. Check whether you have a dependency on 'io.netty:netty-resolver-dns-native-macos'
24-08-01.22:23:17.101 [redisson-netty-1-4] INFO  ConnectionsHolder      - 1 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.22:23:17.110 [redisson-netty-1-13] INFO  ConnectionsHolder      - 5 connections initialized for 127.0.0.1/127.0.0.1:6379
24-08-01.22:23:18.378 [main            ] INFO  EndpointLinksResolver  - Exposing 1 endpoint(s) beneath base path '/actuator'
24-08-01.22:23:18.442 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:23:18.517 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:23:18.517 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:23:18.517 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522198516
24-08-01.22:23:18.526 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Subscribed to topic(s): send_award
24-08-01.22:23:18.530 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:23:18.535 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:23:18.535 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:23:18.535 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522198535
24-08-01.22:23:18.539 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Subscribed to topic(s): activity_sku_stock_zero
24-08-01.22:23:18.546 [main            ] INFO  ConsumerConfig         - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-raffle-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = raffle-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

24-08-01.22:23:18.549 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:23:18.549 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:23:18.549 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522198549
24-08-01.22:23:18.552 [main            ] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Subscribed to topic(s): send_rebate
24-08-01.22:23:18.569 [main            ] INFO  BehaviorRebateServiceTest - Started BehaviorRebateServiceTest in 3.211 seconds (JVM running for 4.269)
24-08-01.22:23:18.779 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-01.22:23:18.779 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting the last seen epoch of partition send_award-0 to 0 since the associated topicId changed from null to Q17VyhiHSOOw5eibgG1l-Q
24-08-01.22:23:18.780 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting the last seen epoch of partition activity_sku_stock_zero-0 to 0 since the associated topicId changed from null to jqFwqYTlTxGdW4b6Nx-a3A
24-08-01.22:23:18.781 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:23:18.781 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:23:18.781 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metadata               - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:23:18.781 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:23:18.781 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:23:18.781 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)
24-08-01.22:23:18.788 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] (Re-)joining group
24-08-01.22:23:18.789 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] (Re-)joining group
24-08-01.22:23:18.790 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] (Re-)joining group
24-08-01.22:23:18.844 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:23:19.141 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:23:19.227 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:23:19.244 [main            ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:23:19.380 [main            ] INFO  ProducerConfig         - Idempotence will be disabled because acks is set to 1, not set to 'all'.
24-08-01.22:23:19.380 [main            ] INFO  ProducerConfig         - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

24-08-01.22:23:19.394 [main            ] INFO  AppInfoParser          - Kafka version: 3.1.2
24-08-01.22:23:19.394 [main            ] INFO  AppInfoParser          - Kafka commitId: f8c67dc3ae0a3265
24-08-01.22:23:19.394 [main            ] INFO  AppInfoParser          - Kafka startTimeMs: 1722522199394
24-08-01.22:23:19.402 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Resetting the last seen epoch of partition send_rebate-0 to 0 since the associated topicId changed from null to 1w6y4glpTnyV3pGMgg28Sg
24-08-01.22:23:19.402 [kafka-producer-network-thread | producer-1] INFO  Metadata               - [Producer clientId=producer-1] Cluster ID: rB2EuGLvQdi61OETC-XyQw
24-08-01.22:23:19.412 [main            ] INFO  EventPublisher         - 发送MQ消息 topic:send_rebate message:{"data":{"bizId":"dzc_sku_2024042906","rebateConfig":"9011","rebateType":"sku","userId":"dzc"},"id":"84583863996","timestamp":1722522199224}
24-08-01.22:23:19.430 [main            ] INFO  EventPublisher         - 发送MQ消息 topic:send_rebate message:{"data":{"bizId":"dzc_integral_2024042906","rebateConfig":"10","rebateType":"integral","userId":"dzc"},"id":"04270137370","timestamp":1722522199226}
24-08-01.22:23:19.445 [main            ] INFO  BehaviorRebateServiceTest - 请求参数：{"behaviorTypeVO":"SIGN","outBusinessNo":"2024042906","userId":"dzc"}
24-08-01.22:23:19.449 [main            ] INFO  BehaviorRebateServiceTest - 测试结果：["599856573546","774763211247"]
24-08-01.22:23:20.008 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Starting...
24-08-01.22:23:20.019 [scheduling-1    ] INFO  HikariDataSource       - Retail_HikariCP - Start completed.
24-08-01.22:23:27.393 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8571 ms.
24-08-01.22:23:27.399 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:23:27.401 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 2147483646 due to socket connection setup timeout. The timeout value is 8531 ms.
24-08-01.22:23:27.401 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:23:29.454 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 2147483646 disconnected.
24-08-01.22:23:29.455 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 2147483646 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:23:29.455 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Group coordinator kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
24-08-01.22:23:30.445 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 11032 ms.
24-08-01.22:23:38.381 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 8877 ms.
24-08-01.22:23:38.460 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 11028 ms.
24-08-01.22:23:38.931 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 11502 ms.
24-08-01.22:23:50.515 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Node 1 disconnected.
24-08-01.22:23:50.517 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:23:50.517 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Node 1 disconnected.
24-08-01.22:23:50.515 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Node 1 disconnected.
24-08-01.22:23:50.517 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:23:50.517 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] WARN  NetworkClient          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Connection to node 1 (kafka/10.89.68.210:9092) could not be established. Broker may not be available.
24-08-01.22:23:51.121 [kafka-producer-network-thread | producer-1] INFO  NetworkClient          - [Producer clientId=producer-1] Disconnecting from node 1 due to socket connection setup timeout. The timeout value is 20581 ms.
24-08-01.22:23:56.653 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:23:56.653 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:23:56.654 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:23:56.654 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:23:56.654 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:23:56.654 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:23:56.654 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:23:56.654 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:23:56.654 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaConsumer          - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Unsubscribed all topics or patterns and assigned partitions
24-08-01.22:23:56.655 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:23:56.655 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-1, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:23:56.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:23:56.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Resetting generation due to: consumer pro-actively leaving the group
24-08-01.22:23:56.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-2, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:23:56.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  ConsumerCoordinator    - [Consumer clientId=consumer-raffle-group-3, groupId=raffle-group] Request joining group due to: consumer pro-actively leaving the group
24-08-01.22:23:56.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:23:56.657 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:23:56.657 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:23:56.657 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:23:56.657 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:23:56.657 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:23:56.657 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics scheduler closed
24-08-01.22:23:56.657 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Closing reporter org.apache.kafka.common.metrics.JmxReporter
24-08-01.22:23:56.658 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  Metrics                - Metrics reporters closed
24-08-01.22:23:56.672 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-2 unregistered
24-08-01.22:23:56.672 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:23:56.672 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-3 unregistered
24-08-01.22:23:56.673 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:23:56.673 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  AppInfoParser          - App info kafka.consumer for consumer-raffle-group-1 unregistered
24-08-01.22:23:56.673 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  KafkaMessageListenerContainer - raffle-group: Consumer stopped
24-08-01.22:23:56.681 [SpringApplicationShutdownHook] INFO  KafkaProducer          - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
